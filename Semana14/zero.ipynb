{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Red Neuronal Convolucional desde Cero para Detección de Edad y Género\n",
    "\n",
    "Este notebook implementa una CNN completamente personalizada sin usar modelos pre-entrenados. Construiremos la arquitectura desde cero utilizando las capas básicas de TensorFlow/Keras.\n",
    "\n",
    "## Objetivos:\n",
    "1. **Crear una CNN personalizada** con capas convolucionales, pooling y densas\n",
    "2. **Implementar dos modelos separados** para clasificación de género y edad\n",
    "3. **Optimizar la arquitectura** con técnicas de regularización\n",
    "4. **Monitorear métricas detalladas** durante el entrenamiento\n",
    "5. **Comparar el rendimiento** con modelos pre-entrenados\n",
    "\n",
    "## Ventajas de crear desde cero:\n",
    "- **Control total** sobre la arquitectura\n",
    "- **Menor tamaño** del modelo final\n",
    "- **Comprensión completa** de cada componente\n",
    "- **Optimización específica** para nuestro problema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones necesarias\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    "\n",
    "# Configuración de GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPU detectadas: {len(gpus)}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"Usando CPU para el entrenamiento\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Configuración de Parámetros\n",
    "\n",
    "Definimos los hiperparámetros y configuraciones del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros de la imagen y entrenamiento\n",
    "IMG_HEIGHT = 64      # Tamaño reducido para entrenar desde cero más rápido\n",
    "IMG_WIDTH = 64       # Podemos usar 128x128 o 224x224 para mejor precisión\n",
    "IMG_CHANNELS = 3     # RGB\n",
    "IMG_SIZE = (IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Clases de clasificación\n",
    "GENDER_CLASSES = ['female', 'male']\n",
    "AGE_CLASSES = ['0-2', '4-6', '8-12', '15-20', '25-32', '38-43', '48-53', '60-100']\n",
    "\n",
    "NUM_GENDER_CLASSES = len(GENDER_CLASSES)\n",
    "NUM_AGE_CLASSES = len(AGE_CLASSES)\n",
    "\n",
    "# Rutas de datos (misma estructura que antes)\n",
    "GENDER_TRAIN_DIR = \"dataset/gender/train\"\n",
    "GENDER_VAL_DIR = \"dataset/gender/validation\"\n",
    "AGE_TRAIN_DIR = \"dataset/age/train\"\n",
    "AGE_VAL_DIR = \"dataset/age/validation\"\n",
    "\n",
    "print(f\"Configuración del modelo:\")\n",
    "print(f\"- Tamaño de imagen: {IMG_SIZE}\")\n",
    "print(f\"- Clases de género: {NUM_GENDER_CLASSES}\")\n",
    "print(f\"- Clases de edad: {NUM_AGE_CLASSES}\")\n",
    "print(f\"- Batch size: {BATCH_SIZE}\")\n",
    "print(f\"- Épocas: {EPOCHS}\")\n",
    "print(f\"- Learning rate: {LEARNING_RATE}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Arquitectura CNN Personalizada\n",
    "\n",
    "### 2.1 Diseño de la arquitectura\n",
    "\n",
    "Nuestra CNN seguirá el patrón clásico:\n",
    "1. **Bloques Convolucionales**: Conv2D → BatchNorm → ReLU → MaxPool\n",
    "2. **Extracción de características**: Múltiples bloques con filtros crecientes\n",
    "3. **Clasificación**: Flatten → Dense → Dropout → Dense final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conv_block(input_layer, filters, kernel_size=(3, 3), pool_size=(2, 2), \n",
    "                      dropout_rate=0.25, l2_reg=1e-4):\n",
    "    \"\"\"\n",
    "    Crea un bloque convolucional estándar\n",
    "    \n",
    "    Args:\n",
    "        input_layer: Capa de entrada\n",
    "        filters: Número de filtros convolucionales\n",
    "        kernel_size: Tamaño del kernel\n",
    "        pool_size: Tamaño del pooling\n",
    "        dropout_rate: Tasa de dropout\n",
    "        l2_reg: Regularización L2\n",
    "    \n",
    "    Returns:\n",
    "        Capa de salida del bloque\n",
    "    \"\"\"\n",
    "    \n",
    "    # Primera convolución\n",
    "    x = layers.Conv2D(\n",
    "        filters, \n",
    "        kernel_size, \n",
    "        padding='same',\n",
    "        kernel_regularizer=l2(l2_reg)\n",
    "    )(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # Segunda convolución (más profundidad)\n",
    "    x = layers.Conv2D(\n",
    "        filters, \n",
    "        kernel_size, \n",
    "        padding='same',\n",
    "        kernel_regularizer=l2(l2_reg)\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # MaxPooling y Dropout\n",
    "    x = layers.MaxPooling2D(pool_size)(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "print(\"Función de bloque convolucional definida\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 2.2 Función principal para crear el modelo CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_cnn(input_shape, num_classes, model_name=\"custom_cnn\"):\n",
    "    \"\"\"\n",
    "    Crea una CNN personalizada desde cero\n",
    "    \n",
    "    Arquitectura:\n",
    "    - Input: (64, 64, 3)\n",
    "    - Conv Block 1: 32 filtros → (32, 32, 32)\n",
    "    - Conv Block 2: 64 filtros → (16, 16, 64)  \n",
    "    - Conv Block 3: 128 filtros → (8, 8, 128)\n",
    "    - Conv Block 4: 256 filtros → (4, 4, 256)\n",
    "    - Global Average Pooling\n",
    "    - Dense: 512 → Dropout → Dense: 256 → Dropout → Output\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Forma de entrada (height, width, channels)\n",
    "        num_classes: Número de clases de salida\n",
    "        model_name: Nombre del modelo\n",
    "    \n",
    "    Returns:\n",
    "        Modelo compilado\n",
    "    \"\"\"\n",
    "    \n",
    "    # Capa de entrada\n",
    "    inputs = layers.Input(shape=input_shape, name='input_layer')\n",
    "    \n",
    "    # Bloque 1: 32 filtros\n",
    "    x = create_conv_block(inputs, 32, dropout_rate=0.25)\n",
    "    \n",
    "    # Bloque 2: 64 filtros  \n",
    "    x = create_conv_block(x, 64, dropout_rate=0.25)\n",
    "    \n",
    "    # Bloque 3: 128 filtros\n",
    "    x = create_conv_block(x, 128, dropout_rate=0.3)\n",
    "    \n",
    "    # Bloque 4: 256 filtros\n",
    "    x = create_conv_block(x, 256, dropout_rate=0.3)\n",
    "    \n",
    "    # Global Average Pooling en lugar de Flatten (reduce overfitting)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Capas densas finales\n",
    "    x = layers.Dense(512, kernel_regularizer=l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = layers.Dense(256, kernel_regularizer=l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    # Capa de salida\n",
    "    if num_classes == 2:\n",
    "        # Clasificación binaria (género)\n",
    "        outputs = layers.Dense(1, activation='sigmoid', name='predictions')(x)\n",
    "    else:\n",
    "        # Clasificación multiclase (edad)\n",
    "        outputs = layers.Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "    \n",
    "    # Crear el modelo\n",
    "    model = models.Model(inputs=inputs, outputs=outputs, name=model_name)\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"Función de creación de CNN personalizada definida\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 2.3 Creación de los modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la forma de entrada\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "\n",
    "# === MODELO DE GÉNERO (CLASIFICACIÓN BINARIA) ===\n",
    "print(\"=== CREANDO MODELO DE GÉNERO ===\")\n",
    "gender_model = create_custom_cnn(\n",
    "    input_shape=input_shape,\n",
    "    num_classes=2,  # Binario: female/male\n",
    "    model_name=\"gender_cnn\"\n",
    ")\n",
    "\n",
    "# Compilar modelo de género\n",
    "gender_model.compile(\n",
    "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='binary_crossentropy',  # Para clasificación binaria\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "print(\"Resumen del modelo de género:\")\n",
    "gender_model.summary()\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*50)\n",
    "\n",
    "# === MODELO DE EDAD (CLASIFICACIÓN MULTICLASE) ===\n",
    "print(\"=== CREANDO MODELO DE EDAD ===\")\n",
    "age_model = create_custom_cnn(\n",
    "    input_shape=input_shape,\n",
    "    num_classes=NUM_AGE_CLASSES,  # 8 clases de edad\n",
    "    model_name=\"age_cnn\"\n",
    ")\n",
    "\n",
    "# Compilar modelo de edad\n",
    "age_model.compile(\n",
    "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='categorical_crossentropy',  # Para clasificación multiclase\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "print(\"Resumen del modelo de edad:\")\n",
    "age_model.summary()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Preparación de Datos\n",
    "\n",
    "### 3.1 Generadores de datos con augmentación avanzada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generador de datos para entrenamiento con augmentación agresiva\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,                    # Normalización\n",
    "    rotation_range=30,                 # Rotación más amplia\n",
    "    width_shift_range=0.3,             # Desplazamiento horizontal\n",
    "    height_shift_range=0.3,            # Desplazamiento vertical\n",
    "    shear_range=0.3,                   # Transformación de corte\n",
    "    zoom_range=0.3,                    # Zoom aleatorio\n",
    "    horizontal_flip=True,              # Volteo horizontal\n",
    "    vertical_flip=False,               # No volteo vertical (rostos)\n",
    "    brightness_range=[0.8, 1.2],      # Variación de brillo\n",
    "    fill_mode='nearest',               # Relleno de píxeles\n",
    "    validation_split=0.2               # Separar 20% para validación\n",
    ")\n",
    "\n",
    "# Generador para validación (solo normalización)\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "def create_data_generators_custom(train_dir, target_size, batch_size, class_mode='categorical'):\n",
    "    \"\"\"\n",
    "    Crea generadores de datos optimizados para entrenamiento desde cero\n",
    "    \n",
    "    Args:\n",
    "        train_dir: Directorio de datos de entrenamiento\n",
    "        target_size: Tamaño objetivo de las imágenes\n",
    "        batch_size: Tamaño del lote\n",
    "        class_mode: Tipo de clasificación\n",
    "    \n",
    "    Returns:\n",
    "        train_generator, validation_generator\n",
    "    \"\"\"\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=class_mode,\n",
    "        subset='training',                # Usar subset de entrenamiento\n",
    "        shuffle=True,\n",
    "        seed=42                          # Para reproducibilidad\n",
    "    )\n",
    "    \n",
    "    validation_generator = val_datagen.flow_from_directory(\n",
    "        train_dir,                        # Mismo directorio, diferente subset\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=class_mode,\n",
    "        subset='validation',              # Subset de validación\n",
    "        shuffle=False,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    return train_generator, validation_generator\n",
    "\n",
    "print(\"Generadores de datos personalizados configurados\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Callbacks y Optimización\n",
    "\n",
    "### 4.1 Callbacks avanzados para monitoreo y control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks_custom(model_name, patience=15):\n",
    "    \"\"\"\n",
    "    Crea callbacks optimizados para entrenamiento desde cero\n",
    "    \n",
    "    Args:\n",
    "        model_name: Nombre del modelo para guardar\n",
    "        patience: Paciencia para early stopping\n",
    "    \n",
    "    Returns:\n",
    "        Lista de callbacks\n",
    "    \"\"\"\n",
    "    \n",
    "    callbacks = [\n",
    "        # Checkpoint del mejor modelo\n",
    "        ModelCheckpoint(\n",
    "            filepath=f'best_{model_name}_custom.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Early stopping con más paciencia para modelos desde cero\n",
    "        EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=patience,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1,\n",
    "            min_delta=0.001  # Mejora mínima requerida\n",
    "        ),\n",
    "        \n",
    "        # Reducir learning rate cuando se estanque\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.3,          # Reducir a 30% del valor actual\n",
    "            patience=8,          # Esperar 8 épocas sin mejora\n",
    "            min_lr=1e-7,         # Learning rate mínimo\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Callback personalizado para métricas\n",
    "        keras.callbacks.CSVLogger(f'{model_name}_training_log.csv')\n",
    "    ]\n",
    "    \n",
    "    return callbacks\n",
    "\n",
    "# Crear callbacks para ambos modelos\n",
    "gender_callbacks = get_callbacks_custom('gender_model', patience=20)\n",
    "age_callbacks = get_callbacks_custom('age_model', patience=20)\n",
    "\n",
    "print(\"Callbacks personalizados configurados\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Entrenamiento de los Modelos\n",
    "\n",
    "### 5.1 Código de entrenamiento para el modelo de género\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRENAMIENTO DEL MODELO DE GÉNERO\n",
    "# (Código comentado para demostración - descomentar para ejecutar)\n",
    "\n",
    "\"\"\"\n",
    "# Crear generadores de datos para género\n",
    "print(\"Creando generadores de datos para género...\")\n",
    "gender_train_gen, gender_val_gen = create_data_generators_custom(\n",
    "    GENDER_TRAIN_DIR,\n",
    "    IMG_SIZE,\n",
    "    BATCH_SIZE,\n",
    "    'binary'  # Clasificación binaria para género\n",
    ")\n",
    "\n",
    "print(f\"Clases encontradas: {gender_train_gen.class_indices}\")\n",
    "print(f\"Muestras de entrenamiento: {gender_train_gen.samples}\")\n",
    "print(f\"Muestras de validación: {gender_val_gen.samples}\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "print(\"\\\\nIniciando entrenamiento del modelo de género...\")\n",
    "history_gender = gender_model.fit(\n",
    "    gender_train_gen,\n",
    "    steps_per_epoch=gender_train_gen.samples // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=gender_val_gen,\n",
    "    validation_steps=gender_val_gen.samples // BATCH_SIZE,\n",
    "    callbacks=gender_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Guardar el modelo final\n",
    "gender_model.save('custom_gender_model.h5')\n",
    "print(\"Modelo de género guardado como 'custom_gender_model.h5'\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Código de entrenamiento del modelo de género preparado\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 5.2 Código de entrenamiento para el modelo de edad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRENAMIENTO DEL MODELO DE EDAD\n",
    "# (Código comentado para demostración - descomentar para ejecutar)\n",
    "\n",
    "\"\"\"\n",
    "# Crear generadores de datos para edad\n",
    "print(\"Creando generadores de datos para edad...\")\n",
    "age_train_gen, age_val_gen = create_data_generators_custom(\n",
    "    AGE_TRAIN_DIR,\n",
    "    IMG_SIZE,\n",
    "    BATCH_SIZE,\n",
    "    'categorical'  # Clasificación multiclase para edad\n",
    ")\n",
    "\n",
    "print(f\"Clases encontradas: {age_train_gen.class_indices}\")\n",
    "print(f\"Muestras de entrenamiento: {age_train_gen.samples}\")\n",
    "print(f\"Muestras de validación: {age_val_gen.samples}\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "print(\"\\\\nIniciando entrenamiento del modelo de edad...\")\n",
    "history_age = age_model.fit(\n",
    "    age_train_gen,\n",
    "    steps_per_epoch=age_train_gen.samples // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=age_val_gen,\n",
    "    validation_steps=age_val_gen.samples // BATCH_SIZE,\n",
    "    callbacks=age_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Guardar el modelo final\n",
    "age_model.save('custom_age_model.h5')\n",
    "print(\"Modelo de edad guardado como 'custom_age_model.h5'\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Código de entrenamiento del modelo de edad preparado\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. Visualización y Análisis de Resultados\n",
    "\n",
    "### 6.1 Función de visualización avanzada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_metrics(history, model_name, save_plots=True):\n",
    "    \"\"\"\n",
    "    Visualiza métricas de entrenamiento con análisis detallado\n",
    "    \n",
    "    Args:\n",
    "        history: Historial de entrenamiento\n",
    "        model_name: Nombre del modelo\n",
    "        save_plots: Si guardar las gráficas\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle(f'Análisis de Entrenamiento - {model_name}', fontsize=16, y=0.98)\n",
    "    \n",
    "    epochs = range(1, len(history.history['accuracy']) + 1)\n",
    "    \n",
    "    # 1. Precisión (Accuracy)\n",
    "    axes[0, 0].plot(epochs, history.history['accuracy'], 'b-', label='Entrenamiento', linewidth=2)\n",
    "    axes[0, 0].plot(epochs, history.history['val_accuracy'], 'r-', label='Validación', linewidth=2)\n",
    "    axes[0, 0].set_title('Precisión del Modelo')\n",
    "    axes[0, 0].set_xlabel('Época')\n",
    "    axes[0, 0].set_ylabel('Precisión')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Pérdida (Loss)\n",
    "    axes[0, 1].plot(epochs, history.history['loss'], 'b-', label='Entrenamiento', linewidth=2)\n",
    "    axes[0, 1].plot(epochs, history.history['val_loss'], 'r-', label='Validación', linewidth=2)\n",
    "    axes[0, 1].set_title('Pérdida del Modelo')\n",
    "    axes[0, 1].set_xlabel('Época')\n",
    "    axes[0, 1].set_ylabel('Pérdida')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Precisión (Precision)\n",
    "    axes[0, 2].plot(epochs, history.history['precision'], 'b-', label='Entrenamiento', linewidth=2)\n",
    "    axes[0, 2].plot(epochs, history.history['val_precision'], 'r-', label='Validación', linewidth=2)\n",
    "    axes[0, 2].set_title('Precisión (Precision)')\n",
    "    axes[0, 2].set_xlabel('Época')\n",
    "    axes[0, 2].set_ylabel('Precisión')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Recall\n",
    "    axes[1, 0].plot(epochs, history.history['recall'], 'b-', label='Entrenamiento', linewidth=2)\n",
    "    axes[1, 0].plot(epochs, history.history['val_recall'], 'r-', label='Validación', linewidth=2)\n",
    "    axes[1, 0].set_title('Recall')\n",
    "    axes[1, 0].set_xlabel('Época')\n",
    "    axes[1, 0].set_ylabel('Recall')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Learning Rate (si está disponible)\n",
    "    if 'lr' in history.history:\n",
    "        axes[1, 1].plot(epochs, history.history['lr'], 'g-', linewidth=2)\n",
    "        axes[1, 1].set_title('Tasa de Aprendizaje')\n",
    "        axes[1, 1].set_xlabel('Época')\n",
    "        axes[1, 1].set_ylabel('Learning Rate')\n",
    "        axes[1, 1].set_yscale('log')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[1, 1].text(0.5, 0.5, 'Learning Rate\\\\nno disponible', \n",
    "                       ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "        axes[1, 1].set_title('Tasa de Aprendizaje')\n",
    "    \n",
    "    # 6. Análisis de overfitting\n",
    "    train_acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    overfitting = [abs(t - v) for t, v in zip(train_acc, val_acc)]\n",
    "    \n",
    "    axes[1, 2].plot(epochs, overfitting, 'purple', linewidth=2)\n",
    "    axes[1, 2].set_title('Análisis de Overfitting')\n",
    "    axes[1, 2].set_xlabel('Época')\n",
    "    axes[1, 2].set_ylabel('Diferencia Train-Val Accuracy')\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_plots:\n",
    "        plt.savefig(f'{model_name}_training_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Estadísticas finales\n",
    "    print(f\"\\\\n=== ESTADÍSTICAS FINALES - {model_name} ===\")\n",
    "    print(f\"Mejor precisión de validación: {max(val_acc):.4f}\")\n",
    "    print(f\"Última precisión de entrenamiento: {train_acc[-1]:.4f}\")\n",
    "    print(f\"Diferencia final train-val: {abs(train_acc[-1] - val_acc[-1]):.4f}\")\n",
    "    print(f\"Épocas completadas: {len(epochs)}\")\n",
    "\n",
    "print(\"Función de visualización avanzada definida\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 6.2 Evaluación detallada del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_detailed(model, test_generator, class_names, model_name):\n",
    "    \"\"\"\n",
    "    Evaluación completa del modelo con métricas detalladas\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo entrenado\n",
    "        test_generator: Generador de datos de prueba\n",
    "        class_names: Lista de nombres de clases\n",
    "        model_name: Nombre del modelo\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\\\n{'='*60}\")\n",
    "    print(f\"EVALUACIÓN DETALLADA - {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Resetear el generador\n",
    "    test_generator.reset()\n",
    "    \n",
    "    # Predicciones\n",
    "    print(\"Generando predicciones...\")\n",
    "    predictions = model.predict(test_generator, verbose=1)\n",
    "    \n",
    "    # Procesar predicciones según el tipo de modelo\n",
    "    if len(class_names) == 2:  # Clasificación binaria\n",
    "        predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
    "    else:  # Clasificación multiclase\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Etiquetas verdaderas\n",
    "    true_classes = test_generator.classes[:len(predicted_classes)]\n",
    "    \n",
    "    # Métricas básicas\n",
    "    accuracy = np.mean(predicted_classes == true_classes)\n",
    "    print(f\"\\\\nPrecisión general: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    \n",
    "    # Reporte de clasificación detallado\n",
    "    print(f\"\\\\n{'-'*40}\")\n",
    "    print(\"REPORTE DE CLASIFICACIÓN:\")\n",
    "    print(f\"{'-'*40}\")\n",
    "    print(classification_report(true_classes, predicted_classes, \n",
    "                              target_names=class_names, digits=4))\n",
    "    \n",
    "    # Matriz de confusión\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                cbar_kws={'label': 'Número de predicciones'})\n",
    "    plt.title(f'Matriz de Confusión - {model_name}', fontsize=14, pad=20)\n",
    "    plt.xlabel('Predicción', fontsize=12)\n",
    "    plt.ylabel('Etiqueta Real', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{model_name}_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Análisis por clase\n",
    "    print(f\"\\\\n{'-'*40}\")\n",
    "    print(\"ANÁLISIS POR CLASE:\")\n",
    "    print(f\"{'-'*40}\")\n",
    "    \n",
    "    for i, class_name in enumerate(class_names):\n",
    "        class_mask = true_classes == i\n",
    "        if np.sum(class_mask) > 0:\n",
    "            class_accuracy = np.mean(predicted_classes[class_mask] == true_classes[class_mask])\n",
    "            print(f\"{class_name}: {class_accuracy:.4f} ({class_accuracy*100:.2f}%) - {np.sum(class_mask)} muestras\")\n",
    "    \n",
    "    # Análisis de confianza de predicciones\n",
    "    print(f\"\\\\n{'-'*40}\")\n",
    "    print(\"ANÁLISIS DE CONFIANZA:\")\n",
    "    print(f\"{'-'*40}\")\n",
    "    \n",
    "    if len(class_names) == 2:  # Binario\n",
    "        confidence = np.maximum(predictions.flatten(), 1 - predictions.flatten())\n",
    "    else:  # Multiclase\n",
    "        confidence = np.max(predictions, axis=1)\n",
    "    \n",
    "    print(f\"Confianza promedio: {np.mean(confidence):.4f}\")\n",
    "    print(f\"Confianza mínima: {np.min(confidence):.4f}\")\n",
    "    print(f\"Confianza máxima: {np.max(confidence):.4f}\")\n",
    "    print(f\"Desviación estándar: {np.std(confidence):.4f}\")\n",
    "    \n",
    "    # Distribución de confianza\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(confidence, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    plt.title(f'Distribución de Confianza de Predicciones - {model_name}')\n",
    "    plt.xlabel('Confianza')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{model_name}_confidence_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': predictions,\n",
    "        'predicted_classes': predicted_classes,\n",
    "        'true_classes': true_classes,\n",
    "        'confidence': confidence,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "print(\"Función de evaluación detallada definida\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 7. Ejemplo de Uso Completo\n",
    "\n",
    "### 7.1 Flujo de trabajo completo (comentado para demostración)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# FLUJO DE TRABAJO COMPLETO PARA ENTRENAR MODELOS DESDE CERO\n",
    "\n",
    "# 1. Entrenar modelo de género\n",
    "print(\"=== ENTRENAMIENTO DEL MODELO DE GÉNERO ===\")\n",
    "gender_train_gen, gender_val_gen = create_data_generators_custom(\n",
    "    GENDER_TRAIN_DIR, IMG_SIZE, BATCH_SIZE, 'binary'\n",
    ")\n",
    "\n",
    "history_gender = gender_model.fit(\n",
    "    gender_train_gen,\n",
    "    steps_per_epoch=gender_train_gen.samples // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=gender_val_gen,\n",
    "    validation_steps=gender_val_gen.samples // BATCH_SIZE,\n",
    "    callbacks=gender_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 2. Visualizar resultados del entrenamiento de género\n",
    "plot_training_metrics(history_gender, \"Modelo de Género Custom\")\n",
    "\n",
    "# 3. Evaluar modelo de género\n",
    "gender_results = evaluate_model_detailed(\n",
    "    gender_model, gender_val_gen, GENDER_CLASSES, \"Género Custom\"\n",
    ")\n",
    "\n",
    "# 4. Guardar modelo de género\n",
    "gender_model.save('custom_gender_model_final.h5')\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*80)\n",
    "\n",
    "# 5. Entrenar modelo de edad\n",
    "print(\"=== ENTRENAMIENTO DEL MODELO DE EDAD ===\")\n",
    "age_train_gen, age_val_gen = create_data_generators_custom(\n",
    "    AGE_TRAIN_DIR, IMG_SIZE, BATCH_SIZE, 'categorical'\n",
    ")\n",
    "\n",
    "history_age = age_model.fit(\n",
    "    age_train_gen,\n",
    "    steps_per_epoch=age_train_gen.samples // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=age_val_gen,\n",
    "    validation_steps=age_val_gen.samples // BATCH_SIZE,\n",
    "    callbacks=age_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 6. Visualizar resultados del entrenamiento de edad\n",
    "plot_training_metrics(history_age, \"Modelo de Edad Custom\")\n",
    "\n",
    "# 7. Evaluar modelo de edad\n",
    "age_results = evaluate_model_detailed(\n",
    "    age_model, age_val_gen, AGE_CLASSES, \"Edad Custom\"\n",
    ")\n",
    "\n",
    "# 8. Guardar modelo de edad\n",
    "age_model.save('custom_age_model_final.h5')\n",
    "\n",
    "# 9. Comparar resultados\n",
    "print(\"\\\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN FINAL:\")\n",
    "print(f\"Precisión modelo de género: {gender_results['accuracy']:.4f}\")\n",
    "print(f\"Precisión modelo de edad: {age_results['accuracy']:.4f}\")\n",
    "print(\"=\"*80)\n",
    "\"\"\"\n",
    "\n",
    "print(\"Flujo de trabajo completo definido (comentado para demostración)\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 8. Resumen de la Arquitectura\n",
    "\n",
    "### Características principales del modelo CNN personalizado:\n",
    "\n",
    "1. **Arquitectura en capas:**\n",
    "   - **Input Layer**: (64, 64, 3) - Imágenes RGB de 64x64 píxeles\n",
    "   - **Conv Block 1**: 32 filtros 3x3 → BatchNorm → ReLU → Conv 32 → BatchNorm → ReLU → MaxPool → Dropout(0.25)\n",
    "   - **Conv Block 2**: 64 filtros 3x3 → BatchNorm → ReLU → Conv 64 → BatchNorm → ReLU → MaxPool → Dropout(0.25)  \n",
    "   - **Conv Block 3**: 128 filtros 3x3 → BatchNorm → ReLU → Conv 128 → BatchNorm → ReLU → MaxPool → Dropout(0.3)\n",
    "   - **Conv Block 4**: 256 filtros 3x3 → BatchNorm → ReLU → Conv 256 → BatchNorm → ReLU → MaxPool → Dropout(0.3)\n",
    "   - **Global Average Pooling**: Reduce dimensiones y previene overfitting\n",
    "   - **Dense 1**: 512 neuronas → BatchNorm → ReLU → Dropout(0.5)\n",
    "   - **Dense 2**: 256 neuronas → BatchNorm → ReLU → Dropout(0.5)\n",
    "   - **Output**: 1 neurona (género) o 8 neuronas (edad) con activación correspondiente\n",
    "\n",
    "2. **Técnicas de regularización:**\n",
    "   - **BatchNormalization**: Estabiliza el entrenamiento\n",
    "   - **Dropout**: Previene overfitting (0.25-0.5)\n",
    "   - **L2 Regularization**: En capas convolucionales y densas\n",
    "   - **Global Average Pooling**: Reduce parámetros vs Flatten\n",
    "\n",
    "3. **Optimizaciones:**\n",
    "   - **Data Augmentation**: Rotación, desplazamiento, zoom, brillo\n",
    "   - **Learning Rate Scheduling**: Reducción automática cuando se estanca\n",
    "   - **Early Stopping**: Para evitar sobreentrenamiento\n",
    "   - **Model Checkpointing**: Guardar mejor modelo automáticamente\n",
    "\n",
    "4. **Ventajas vs Transfer Learning:**\n",
    "   - ✅ **Modelo más pequeño** (~10MB vs ~50MB)\n",
    "   - ✅ **Control total** de la arquitectura\n",
    "   - ✅ **Entrenamiento específico** para el problema\n",
    "   - ✅ **Mejor comprensión** del modelo\n",
    "   - ❌ **Requiere más datos** para buen rendimiento\n",
    "   - ❌ **Entrenamiento más largo** desde cero\n",
    "   - ❌ **Posiblemente menor precisión** inicial\n",
    "\n",
    "Este notebook proporciona una base sólida para entrenar modelos CNN personalizados para detección de edad y género, con todas las mejores prácticas implementadas.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
